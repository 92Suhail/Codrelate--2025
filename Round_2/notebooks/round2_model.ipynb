# AI-Powered Content Analysis - Round 2 Hackathon Solution

# STEP 1: Import Libraries
import pandas as pd
import numpy as np
import re
import string
import matplotlib.pyplot as plt
import seaborn as sns
import shap
import joblib

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import classification_report, accuracy_score, f1_score, roc_auc_score
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.multioutput import MultiOutputClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn.preprocessing import MultiLabelBinarizer

import warnings
warnings.filterwarnings("ignore")

# STEP 2: Load Preprocessed Data (from Round 1)
df = pd.read_csv("../data/cleaned_medium_articles.csv")  # change to your actual cleaned CSV

# STEP 3: Feature Engineering
df['reading_time'] = df['text'].apply(lambda x: len(str(x).split()) // 200)
df['title_len'] = df['title'].apply(lambda x: len(str(x)))
df['num_tags'] = df['tags'].apply(lambda x: len(eval(x)))
df['weekday'] = pd.to_datetime(df['timestamp']).dt.dayofweek

# STEP 4: Tag Modeling (Multi-label Classification)
mlb = MultiLabelBinarizer()
y_tags = mlb.fit_transform(df['tags'].apply(eval))

X_text = df['title'] + " " + df['text']
tfidf = TfidfVectorizer(max_features=10000, stop_words='english')
X_tfidf = tfidf.fit_transform(X_text)

X_train, X_test, y_train, y_test = train_test_split(X_tfidf, y_tags, test_size=0.2, random_state=42)

model_tag = MultiOutputClassifier(LogisticRegression(max_iter=1000))
model_tag.fit(X_train, y_train)
y_pred_tags = model_tag.predict(X_test)

print("Tag Modeling F1 Score:", f1_score(y_test, y_pred_tags, average="micro"))

# STEP 5: Engagement Prediction (Binary Classification)
df['is_popular'] = df['claps'].apply(lambda x: 1 if x > df['claps'].median() else 0)

features = ['reading_time', 'title_len', 'num_tags', 'weekday']
X_engage = df[features]
y_engage = df['is_popular']

X_train_e, X_test_e, y_train_e, y_test_e = train_test_split(X_engage, y_engage, test_size=0.2, random_state=42)

model_engage = XGBClassifier(tree_method='hist')
params = {'n_estimators': [100, 200], 'max_depth': [4, 6]}
grid = GridSearchCV(model_engage, param_grid=params, scoring='f1', cv=3)
grid.fit(X_train_e, y_train_e)

best_model_engage = grid.best_estimator_
y_pred_engage = best_model_engage.predict(X_test_e)
print("Engagement Accuracy:", accuracy_score(y_test_e, y_pred_engage))
print("F1 Score:", f1_score(y_test_e, y_pred_engage))

# STEP 6: Explainability with SHAP
explainer = shap.Explainer(best_model_engage)
shap_values = explainer(X_test_e[:100])
shap.summary_plot(shap_values, X_test_e[:100])

# STEP 7: Keyword Extraction (Simple TF-IDF Method)
def extract_keywords(text, n=10):
    vec = TfidfVectorizer(stop_words='english', max_features=1000)
    tfidf_matrix = vec.fit_transform([text])
    scores = zip(vec.get_feature_names_out(), tfidf_matrix.sum(axis=0).tolist()[0])
    sorted_keywords = sorted(scores, key=lambda x: x[1], reverse=True)
    return [kw for kw, score in sorted_keywords[:n]]

sample_keywords = extract_keywords(df['text'].iloc[0])
print("Sample Keywords:", sample_keywords)

# STEP 8: Save Models for Frontend Integration
joblib.dump(model_tag, "../models/tag_classifier.pkl")
joblib.dump(best_model_engage, "../models/engagement_model.pkl")
joblib.dump(tfidf, "../models/tfidf_vectorizer.pkl")
joblib.dump(mlb, "../models/tag_mlb.pkl")

# STEP 9: Streamlit Frontend Code Snippet (Separate File)
"""
import streamlit as st
import joblib

model = joblib.load("models/engagement_model.pkl")
tfidf = joblib.load("models/tfidf_vectorizer.pkl")

st.title("AI Content Recommendation & Prediction")
text_input = st.text_area("Paste article title + content")

if st.button("Predict Popularity"):
    X_input = tfidf.transform([text_input])
    pred = model.predict(X_input)
    st.write("Predicted Popularity:", "ðŸ”¥ High" if pred[0] else "ðŸ§Š Low")
"""

# END OF ROUND 2 SOLUTION
